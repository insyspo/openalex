{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNClpJ+5N1o+e5I7SudT/4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insyspo/openalex/blob/main/bash_commands_to_download_and_upload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bash commands: project `insyspo`\n"
      ],
      "metadata": {
        "id": "biHVnXAJjrUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following commands are put in this notebook for documentation and organisation. They are meant to run on a Linux terminal.\n",
        "\n",
        "The steps are:\n",
        "- Download the command line interfaces (CLIs) to operate cloud services.\n",
        "- Download OpenAlex snapshot.\n",
        "- Create dataset and tables inside Google BigQuery.\n",
        "- Upload all the files in tables for each data entity"
      ],
      "metadata": {
        "id": "_qXcXsnL42k-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AWS CLI"
      ],
      "metadata": {
        "id": "XA-VIf6lQL2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command line interface for Amazon Web Services. It is used only to download the snapshot from their storage."
      ],
      "metadata": {
        "id": "7-RtfTvEuT6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install AWS-CLI\n",
        "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
        "unzip awscliv2.zip\n",
        "sudo ./aws/install"
      ],
      "metadata": {
        "id": "RYqawW2Xm5Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download snapshot"
      ],
      "metadata": {
        "id": "GDg6Dtj-QO86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When downloading, check for the free space in the disk. Change the working folder if needed, where you will have writing privileges."
      ],
      "metadata": {
        "id": "6Gj7eigQudYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all files\n",
        "# Take care to download on a disk with enough space.\n",
        "# As of April 2024, 418 GB were needed to contain all the compressed files.\n",
        "aws s3 sync \"s3://openalex\" \"openalex-snapshot\" --no-sign-request"
      ],
      "metadata": {
        "id": "22xRO1DfQPhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCP CLI"
      ],
      "metadata": {
        "id": "yQWaC7TNQUbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command line interface for the Google Cloud Platform.\n",
        "\n",
        "It is used for most of the work. Here we have used on a virtual machine inside GCP, so it was already pre-installed. On a local machine, you should run the commands bellow that are commented. They will ask for online authorisation and logging into a Google Account.\n",
        "\n",
        "We used the CLI for created the tables, dataset and upload the data into them.\n",
        "\n",
        "In our tests, we have used a virtual machine with 4 vCPUs and 16 GB RAM.\n",
        "\n"
      ],
      "metadata": {
        "id": "0OmbWTWIuvTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GCP-CLI already installed.\n",
        "# We did using a Vertex AI notebook with Google tools and credentials installed.\n",
        "# If it is not the case, run:\n",
        "# curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-471.0.0-linux-x86_64.tar.gz\n",
        "# tar -xf google-cloud-cli-471.0.0-linux-x86_64.tar.gz\n",
        "# ./google-cloud-sdk/install.sh\n",
        "# ./google-cloud-sdk/bin/gcloud init\n",
        "# This will require authorisation.\n"
      ],
      "metadata": {
        "id": "L4Oc884yQT61"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset and tables"
      ],
      "metadata": {
        "id": "H_kLyBPZQY21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create dataset\n",
        "# bq mk project_id:dataset_name\n",
        "bq mk insyspo:publicdb_openalex_2024_04\n",
        "\n",
        "# Create tables\n",
        "# bq mk --table project_id:dataset_name.table_name column_name:data_type\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.works work:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.authors author:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.sources source:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.institutions institution:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.publishers publisher:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.funders funder:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.concepts concept:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.merged_ids merged_id:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.topics topic:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.fields field:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.subfields subfield:string\n",
        "bq mk --table insyspo:publicdb_openalex_2024_04.domains domain:string"
      ],
      "metadata": {
        "id": "ZqG8HDKQnwLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload files into tables in BigQuery"
      ],
      "metadata": {
        "id": "NTeH0u93n1hV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A good suggestion to optimise is to put the table `works` in a process and all the others sequentially in another. `works` has the largest files.\n",
        "\n",
        "Two processes could be simply two instaces of the terminal."
      ],
      "metadata": {
        "id": "dgbDjIfMQfUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShecguE3TSiv"
      },
      "outputs": [],
      "source": [
        "# Process one\n",
        "for data_file in openalex-snapshot/data/works/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'work:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.works $data_file;\n",
        "done\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process two\n",
        "for data_file in openalex-snapshot/data/authors/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'author:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.authors $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/sources/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'source:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.sources $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/institutions/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'institution:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.institutions $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/publishers/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'publisher:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.publishers $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/funders/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'funder:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.funders $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/concepts/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'concept:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.concepts $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/merged_ids/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'merged_id:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.merged_ids $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/topics/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'topic:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.topics $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/fields/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'field:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.fields $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/subfields/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'subfield:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.subfields $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/domains/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'domain:string' \\\n",
        "        --project_id insyspo \\\n",
        "        publicdb_openalex_2024_02.domains $data_file;\n",
        "done"
      ],
      "metadata": {
        "id": "1k3MBTbfQoM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different project: `stone-ground-401723`"
      ],
      "metadata": {
        "id": "7w-YWqcJjOKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
        "unzip awscliv2.zip\n",
        "sudo ./aws/install\n",
        "\n",
        "aws s3 sync \"s3://openalex\" \"openalex-snapshot\" --no-sign-request\n",
        "\n",
        "bq mk stone-ground-401723:publicdb_openalex_2024_04\n",
        "\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.works work:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.authors author:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.sources source:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.institutions institution:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.publishers publisher:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.funders funder:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.concepts concept:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.merged_ids merged_id:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.topics topic:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.fields field:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.subfields subfield:string\n",
        "bq mk --table stone-ground-401723:publicdb_openalex_2024_04.domains domain:string"
      ],
      "metadata": {
        "id": "H2sDYltmWIDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_file in openalex-snapshot/data/sources/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'source:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.sources $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/works/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'work:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.works $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/authors/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'author:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.authors $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/institutions/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'institution:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.institutions $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/publishers/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'publisher:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.publishers $data_file;\n",
        "done\n",
        "####\n",
        "for data_file in openalex-snapshot/data/funders/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'funder:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.funders $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/concepts/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'concept:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.concepts $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/merged_ids/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'merged_id:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.merged_ids $data_file;\n",
        "done\n",
        "####\n",
        "for data_file in openalex-snapshot/data/topics/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'topic:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.topics $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/fields/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'field:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.fields $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/subfields/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'subfield:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.subfields $data_file;\n",
        "done\n",
        "\n",
        "for data_file in openalex-snapshot/data/domains/*/*.gz;\n",
        "do\n",
        "    bq load --source_format=CSV -F '\\t' \\\n",
        "        --schema 'domain:string' \\\n",
        "        --project_id stone-ground-401723 \\\n",
        "        publicdb_openalex_2024_04.domains $data_file;\n",
        "done"
      ],
      "metadata": {
        "id": "7pzGRl8WZg6v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}